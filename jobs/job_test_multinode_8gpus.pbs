#!/bin/bash -l
#PBS -A NLDesignProtein
#PBS -N job_test_multinode_8gpus
#PBS -l walltime=00:20:00
#PBS -l select=2
#PBS -l place=scatter
#PBS -l filesystems=home:grand
#PBS -q debug

projdir=${PBS_O_WORKDIR}  # Should submit job from the BioM3-dev directory

cd ${projdir}  # TODO: verify that directory ends in BioM3-dev

module use /soft/modulefiles
module load conda
conda activate base
source venvs/biom3-env/bin/activate

# Set environment variables needed by script
# export WORLD_SIZE=8  # 2 nodes Ã— 4 XPUs per node
# export RANK=0
# export LOCAL_RANK=0
# export NODE_RANK=0
export MASTER_ADDR=$(cat $PBS_NODEFILE | head -n 1)
export MASTER_PORT=29500 # standard pytorch port
NNODES=`wc -l < $PBS_NODEFILE`
NRANKS=4 # Number of MPI ranks to spawn per node
NTOTRANKS=$(( NNODES * NRANKS ))

echo "Master Address: $MASTER_ADDR"
echo "NUM_NODES: ${NNODES}"
echo "TOTAL_NUM_RANKS: ${NTOTRANKS}"
echo "RANKS_PER_NODE: ${NRANKS}"
echo "THREADS_PER_RANK: ${NTHREADS}"

datetime=$(date +%Y%m%d_%H%M%S)

wandb_api_key="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"
configdir=./configs
config_name=config_8gpus

version_name="V${datetime}_${NNODES}_nodes"
epoch=2 # number of epochs
resume_from_checkpoint='null'

./scripts/hydra_PL_train_transformer.sh \
    $wandb_api_key $configdir $config_name \
    $version_name \
    $epoch \
    $resume_from_checkpoint
# > my_log_file.o 2>&1
